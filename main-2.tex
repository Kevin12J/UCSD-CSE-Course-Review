\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{setspace}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{mathtools}

\title{UCSD CSE 21 Review}
\author{Taanish Reja and Kevin Jacob}
\date{Spring 2024}

\begin{document}
\begin{spacing}{1.5}
\maketitle
\newpage

\section*{Table of Contents}

\begin{enumerate}
%Counting Contents
\item \hyperref[sec:counting]{Counting}
\begin{itemize}
\item \hyperref[sec:sets]{Sets}
\begin{itemize}
\item \hyperref[sec:multiset]{Multiset}
\item \hyperref[sec:subset]{Subset}
\end{itemize}
\item \hyperref[sec:product]{Product Rule}
\item \hyperref[sec:sum]{Sum Rule}
\item \hyperref[sec:power]{Power Rule}
\item \hyperref[sec:quotient]{Quotient Rule}
\item \hyperref[sec:inclusionexclusion]{Inclusion Exclusion Principle}
\item \hyperref[sec:complement]{Counting With Complement}
\item \hyperref[sec:permutations]{Permutations}
\item \hyperref[sec:combinations]{Combinations}
\item \hyperref[sec:binomial]{Binomial Coefficients}
\begin{itemize}
    \item \hyperref[sec:symmetry]{Symmetry Identity}
    \item \hyperref[sec:btheorem]{Binomial Theorem}
    \item \hyperref[sec:pascal]{Pascal's Identity}
    \item \hyperref[sec:sidentity]{Sum Identity}
\end{itemize}
\item \hyperref[sec:starsbars]{Stars and Bars}
\item \hyperref[sec:12fold]{The 12-fold way}
\end{itemize}
\newpage
\item \hyperref[sec:probability]{Distributions and Probability}
\begin{itemize}
    \item \hyperref[sec:pbasics]{Probability Basics}
    \item \hyperref[sec:uniform]{Uniform/Non-Uniform distributions}
    \item \hyperref[sec:binomial_distribution]{Binomial Distribution}
    \item \hyperref[sec:conditional]{Conditional Probability}
    \item \hyperref[sec:bayes]{Bayes Theorem}
    \item \hyperref[sec:independence]{Independence}
    \item \hyperref[sec:rsampling]{Random Sampling}
    \item \hyperref[sec:rvariables]{Random variables}
    \item \hyperref[sec:expectation]{Expectation}
    \begin{itemize}
        \item \hyperref[sec:lexpectation]{Linearity of Expectation}
    \end{itemize}
    \item \hyperref[sec:variance]{Variance}
\end{itemize}
\item \hyperref[sec:runtime]{Runtime Analysis{}}
\begin{itemize}
    \item \hyperref[sec:minsort]{Min Sort}
    \item \hyperref[sec:bubblesort]{Bubble Sort}
    \item \hyperref[sec:insertionsort]{Insertion Sort}
    \item \hyperref[sec:linearsearch]{Linear Search}
    \item \hyperref[sec:binarysearch]{Binary Search}
    \item \hyperref[sec:asymptotic]{Asymptotic Classes}
    \begin{itemize}
        \item \hyperref[sec:theta]{Big Theta}
        \item \hyperref[sec:omega]{Big Omega}
        \item \hyperref[sec:littleo]{Little O}
        \item \hyperref[sec:bigo]{Big O}
        \item \hyperref[sec:oproperties]{Big O Class Properties}
        \item \hyperref[sec:functions]{Growth Rate of Common Functions}
        \item \hyperref[sec:disjoint]{Disjoint Lists Function}
    \end{itemize}
    \item \hyperref[sec:rproduct]{Product Rule}
    \item \hyperref[sec:invariant]{Loop Invariant Induction}
    \begin{itemize}
        \item \hyperref[sec:selectionsortproof]{Selection Sort Loop Invariant Induction}
        \item \hyperref[sec:findmaxproof]{Find Max Proof}
    \end{itemize}    
\end{itemize}
\item \hyperref[sec:recursion]{Recursion}
\begin{itemize}
    \item \hyperref[sec:rfindmaxproof]{Recursive Find Max}
    \item \hyperref[sec:mergesort]{Merge Sort (Divide and Conquer)}
    \item \hyperref[sec:master]{Master theorem}
    \item \hyperref[sec:homogenous] {Homogenous recurrence relations}
       \begin{itemize}
       \item \hyperref[sec:domino]{Domino Tilings}
        \item \hyperref[sec:characteristic]{Characteristic polynomial}
        \item \hyperref[sec:fibonacci]{Fibonacci}
    \end{itemize}
    \item \hyperref[sec:rcounting]{Recursive Counting}
    \begin{itemize}
        \item \hyperref[sec:stirling]{Permutations/Stirling's Approximation}
        \item \hyperref[sec:nstring]{n-bit strings}
        \item \hyperref[sec:solver]{Solving Recurrences}
    \end{itemize}
\item \hyperref[sec:encoding]{Encoding}
\begin{itemize}
    \item \hyperref[sec:loss]{Lossy and loseless encoding}
    \item  \hyperref[sec:fwencode]{Fixed Width Encoding}
    \item  \hyperref[sec:huffman]{Huffman Encoding}
    \item  \hyperref[sec:fibencode]{Fibonacci Encoding}
    \item  \hyperref[sec:ranking]{Ranking/Unranking}
    \item  \hyperref[sec:optimal]{Theoretical Best Encoding} 
\end{itemize}
\item \hyperref[sec:graphtheorry]{Graph Theory}
\begin{itemize}
    \item \hyperref[sec:graphs]{Graphs}
    \begin{itemize}
        \item \hyperref[sec:directed]{Directed graphs}
        \item \hyperref[sec:directedac]{Directed Acyclic Graphs}
        \item \hyperref[sec:undirected]{Undirected graphs}
        \item \hyperref[sec:connectedness] {Connectedness}
    \end{itemize}
    \item \hyperref[sec:hamilton]{Hamilitonian paths}
    \item \hyperref[sec:eulerian]{Eulerian paths}
    \item \hyperref[sec:adj]{Adjacency Matrix}
    \item \hyperref[sec:trees]{Trees}
\end{itemize}
\item \hyperref[sec:randalgo]{Randomized Algorithms}
\begin{itemize}
    \item \hyperref[sec:vegas]{Las Vegas Algorithms}
    \item \hyperref[sec:montecarlo]{Monte Carlo Algorithms}
\end{itemize}
\end{itemize}
\end{enumerate}
\newpage
%Sets Section
\subsection{Sets}
\label{sec:sets}
%
\subsubsection{Multi-set}
\label{sec:multiset}
A set that allows for repeats ( {1,1,2,3} )\\
\textbf{Anagram:} A string that is a rearrangement of a multi-set of characters\\
\textbf{Example:} How many anagrams of \text{\color{red}{A}\color{green}{EE}\color{blue}{SSSS}\color{orange}{R}}\\
We need to consider over counting since swapping repeated letters will be the same, so the number we over count by is $2! \times 4!$. Therefore the total number of anagrams is $\frac{8!}{2! \times 4!}$.
%
\subsubsection{Subset}
\label{sec:subset}
A set $A$ is a subset of another set $B$ if $B$ contains all the elements in $A$.\\
\textbf{Example:} finding the number of subsets of k elements from set of n elements\\
To find the number of subsets of k elements from set of n elements, we can do $\binom{n}{k}$
%Counting Section
\section{Counting}
\label{sec:counting}
%
\subsection{Product Rule}
For any set, $|A \times B| = |A||B|$\\
$A \times B = \{(a,b): a\in A, b\in B\}$
\label{sec:product}
%
\subsection{Sum Rule}
\label{sec:sum}
For disjoint sets, $A \cap B = \emptyset$, $A \cup B = A + B$
%
\subsection{Power Rule}
\label{sec:power}
For any set, $|A \times A \times A \times \dots \times A| = |A|^{n}$\\
\textbf{Examples:}
\begin{itemize}
    \item $\text{\# of binary strings of length n} = 2^n$
    \item $\text{\# of strings of length n over alphabet } A = |A|^n$
    \item $\text{\# of n-length sequences consisting of elements from sets of the same cardinality} = |A|^{n}$
    \item $\text{\# of ways to distribute $|A|$ distinct objects among $n$ people} = n^{|A|}$
\end{itemize}
%
\subsection{Quotient Rule}
\label{sec:quotient}
If set $A$ can be partitioned into disjoint sets\\
$X_1, X_2, \dots, X_k$, where $|X_1| = |X_2| = \dots = |X_k|$\\
$k= \frac{|A|}{|X_1|}$\\
\textbf{Example with object symmetries:}
\begin{itemize}
    \item Color a square with 4 colors
    \item $4!$ different ways to order/construct quare
    \item 8 object symmetries (4 rotations and 2 reflections)
\end{itemize}
$\text{\# of theoretical objects} = 4! = 24$\\
$\text{\# of physical objects} = \frac{24}{8} = 3$
%
\subsection{Inclusion Exclusion Principle}
\label{sec:inclusionexclusion}
\textbf{For two sets:} $|A \cup B| = |A| + |B| - |A \cap B|$\\
If $A_1, A_2, \dots, A_n$ are finite sets then\\
\textbf{Generalized:}\\ $|A_1 \cup A_2 \cup \dots \cup A_n| =\\ \sum_{1 \leq i \leq n} |A_i| - \sum_{1 \leq i < j \leq n}|A_i \cap A_j| + \sum_{1 \leq i < j < k \leq n}|A_i \cap A_j \cap A_k| - \dots + (-1)^{n+1}|A_1 \cap A_2 \cap \dots \cap A_n|$\\
\textbf{Example with fixed points:}\\
Take the string $1234$. We can set a fixed point, say, at position 1. This means the 1 will be fixed, and that we can form anagrams by shifting the other positions.\\
We want to figure out how many permutations of length 4 have a fixed point at position 1 or 2 or 3 or 4. To do this, we can use inclusion-exclusion. Let $P_i$ represent the number of permutations at each fixed point $i$.\\
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \sum(P_i) - \sum(P_i \cap P_j) + \sum(P_i \cap P_j \cap P_k) - (P_1 \cap P_2 \cap P_3 \cap P_4)$\\
Here, we use permutations because if one spot is fixed, there is 3 spots we can permutate, etc...
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \sum(3!) - \sum(2!) + \sum(1!) - (0!)$\\
Here, we multiply by $\binom{4}{x}$ because if x positions are fixed, $\binom{4}{x}$ gives us the \# of ways to arrange those fixed positions.\\
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \binom{4}{1}(3!) - \binom{4}{2}(2!) + \binom{4}{3}(1!) - \binom{4}{4}(0!)$\\
Fixed points can be generalized with the formula: \\ $n!\sum_{k=1}^n\frac{(-1)^{k+1}}{k!}$\\
\textbf{Derangements}\\
Using our newly defined fixed points formula, as well as \hyperref[sec:complement]{counting with complements}, we can count derangements, or the number of permutations of the string {1,2,\dots,n} without a fixed point.\\

$n! - n!\sum_{k=1}^n\frac{(-1)^{k+1}}{k!}=\sum_{k=1}^n\frac{(-1)^{k}}{k!}$


%
\subsection{Counting With Complement}
\label{sec:complement}
\textbf{Universal Set ($U$):} Set that contains all elements\\
\textbf{Set ($A$):} Subset of the universal set\\
\textbf{Set Complement ($A^c$):} Set that contains all elements in universal set that aren't in $A$\\
$U = A + A^c$ or $A = U - A^c$\\
\textbf{Example:} How many 4 digit strings of digits 0-9 have at least one 0?\\
$U$ = set of all 4 digits strings where $|U| = 10^4$\\
$A^c$ = set of all strings that don't have 0 where $|A^c| = 9^4$\\
$10^4-9^4$ is the number of 4 digit strings that have at least one 0
%
\subsection{Permutations}
\label{sec:permutations}
\textbf{r-permutations:} \# of ways to arrange $r$ objects out of $n$ objects. (Order matters here, whereas in combinations, order doesn't matter)\\
$P(n,r) = {}_nP{}_r = n(n-1)(n-2)\dots(n-r+1) = \frac{n!}{(n-r)!}$\\
\textbf{n-permutations:} rearrangement of $n$ distinct objects so that each object appears exactly once\\
$n!$\\
\textbf{Example with r words over an alphabet of length n}\\
How many 3 letter words can you form from a 10 letter alphabet?\\
$P(10, 3) = \frac{10!}{(10-7)!}$\\
\textbf{Example with different ways athletes can finish in a race}\\
How many ways can 10 athletes finish in a race?\\
$n! = 10!$

% 
\subsection{Combinations}
\label{sec:combinations}
\# of ways to chose $r$ different elements from a set of n distinct elements
$C(n,r) = \frac{P(n,r)}{r!} = \frac{n!}{r!(n-r)!}$\\
\textbf{Example with $\binom{n}{k}$:}
\begin{itemize}
    \item How many k-element subsets of a set of cardinality n
    \item How many length n binary strings with exactly k ones (density = \# of 1 bits = k)
\end{itemize}
%
\subsection{Binomial Coefficients}
\label{sec:binomial}
\textbf{Binomial coefficient}: $\binom{n}{k}$\\
The number of ways to choose k objects out of a set of k. Order doesn't matter, but since it counts sets, two sets cannot have the same elements.
%
\subsubsection{Symmetry Identity}
\label{sec:symmetry}
\textbf{Symmetry Identity:} $\binom{n}{k} = \binom{n}{n-k}$
%
\subsubsection{Binomial Theorem}
\label{sec:btheorem}
$(x+y)^n = (x+y)(x+y) \dots (x+y) = \binom{n}{0}x^n + \binom{n}{1}x^{n-1}y + \binom{n}{2}x^{n-2}y^2 + \dots + \binom{n}{n-1}xy^{n-1} + \binom{n}{n}y^n$\\
Number of ways we can choose $k$ of $n$ factors to contribute to $y$ and $n-k$ factors to contribute to $x$: $\binom{n}{k{z^{n-k}y^k}}$
%
\subsubsection {Pascal's Identity}
\label{sec:pascal}
\textbf{Pascal's Identity} $\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$\\
\textbf{Example:} Combinatorial Proof\\
Consider Pascal's Identity: $\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$. The left hand side counts the number of strings of length $n+1$ with $k$ 1's. Meanwhile, the right hand side counts the number of length $n$ strings with $k$ 1's plus the number of length $n$ strings with $k-1$ 1's. The number of length $n$ strings with $k$ 1's is the same as the number of length $n+1$ strings with a 0 in the first term and $k$ 1's in the last $n$ terms, and the number of length $n$ strings with $k-1$ 1's counts the number of length $n+1$ strings with a 1 in the first term and $k-1$ 1's in the last $n$ terms. Thus, the sum of these terms counts the number of length $n+1$ strings with $k$ 1's. Therefore, the LHS and RHS are the same.
%
\subsubsection {Sum Identity}
\label{sec:sidentity}
$\sum_{k=0}^n \binom{n}{k} = 2^n$
%
\subsection {Stars and Bars}
\label{sec:starsbars}
\# of ways to put $n$ indistinguishable objects in $k$ groups in $\binom{n+k-1}{k-1}$\\
\textbf{Example:} Partitioning n indistinguishable knights into k castles\\
Here, we can think of the castles as barriers. Thus, the problem becomes the standard stars and bars problem, and can be solved with $\binom{n+k-1}{k-1}$ \\
\textbf{Example:} Integer Equations
\begin{center}
    $a_1+a_2+a_3+a_4 + a_5 = 33$
\end{center}
\underline{How many solutions of positive integers:} $\binom{37}{4}$ since we want to split 33 among 5 variables\\
\underline{Find the number of solutions where at least one variable is less than or equal to 3:} $\binom{37}{4}-\binom{12}{4}$ since we can use counting with complement to subtract the solutions where every number is at least 5 from the total number of solutions.\\
\newpage
\underline{How many solutions of integers where $0\leq a_1\leq 10$, $0\leq a_2\leq 10$, $0\leq a_3\leq 10$, $0\leq a_4\leq 10$, and $0\leq a_5\leq 10$:} $\binom{37}{4}-(\binom{5}{1}\binom{26}{4} - \binom{5}{2}\binom{15}{4} + \binom{5}{3}\binom{4}{4})$ since we consider the cases where we give one, two, or three variable at least 11 in order to break the rule. For the term $\binom{5}{1}\binom{26}{24}$ we account for how many different sets of 1 variable we can select to add11 to and how many ways to distribute the remaining 22 among the variables. We have to consider the inclusion exclusion principle since we have to consider all the cases when one, two, or three variables have a minimum of 11. We subtract the total number of ways that don't satisfy the inequalities from the total number of solutions in order to get the answer.\\
\subsection{The 12-fold way}
\label{sec:12fold}
\begin{tabular}{|c|c|c|c|c|}
    \hline
    Elements of $N$ & Elements of $X$ & Any $f$ & $f$ injextive & $f$ surjective\\
    \hline
    Distinguishable & Distinguishable & $x^n$ & $P(X, N)$ & inclusion/exclusion, counting with complement \\
    Indistinguishable & Distinguishable & $\binom{n+x-1}{x-1}$ & $\binom{X}{N}$ & $\binom{n-1}{x-1}$/at least one item in each group\\
    \hline
\end{tabular}
%
\section{Distributions and Probability}
\label{sec:probability}
\subsection{Basics}
\label{sec:pbasics}
\textbf{Sample Space:} A set where outcomes in probability are elements of the sample space\\
\textbf{Events:} subsets of the sample space
\begin{center}
    sample space of rolling a six-sided die is $\{1,2,3,4,5,6\}$
\end{center}
\textbf{Distribution:} A function from the sample space to [0,1]\\
$f: \Omega \rightarrow [0,1]$
\subsection{Uniform/Non-uniform Distribution}
\label{sec:uniform}
Given sample space $S$, in a uniform distribution, for any event $E$, $p(E)=|E|/|S|$\\
Non-uniform distributions: Any distribution that is not uniform, i.e. all events do NOT have the same probability.
\subsection{Binomial Distribution}
\label{sec:binomial_distribution}
\textbf{Bernoulli Trial:} a performance of an experiment with two possible outcomes\\
\textbf{Binomial distribution:} probability of exactly $k$ successes in $n$ independent Bernoulli trials, when the probability of success is $p$.
\begin{center}
Prob($k$)$ = \binom{n}{k}p^k(1-p)^{n-k}$
\end{center}
\subsection{Conditional Probability}
$P(A|B) = \frac{P(A \cap B)}{P(B)}$
\subsection{Bayes Theorem}
\label{sec:bayes}
\textbf{Bayes Theorem:}
$P(A|B) = \frac{P(B|A)P(A)}{P(B)}=\frac{P(B|A)P(A)}{\sum_jP(B|A_i)P(A_I)}$\\
\textbf{Law of Total Probability:} $P(E) = P(E|F)P(F) + P(E|\overline{F})P(\overline{F})$\\
\textbf{Generalized Law of Total Probability:} $P(A) = \sum_jP(A_j|B)P(B)=\sum_jP(A_j \cap B)$
\label{sec:conditional}
\subsection{Independence}
\label{sec:independence}
Two events E and F are independent if the occurence of one event does not affect the likelihood of the other event\\
$P(E|F) = P(E)$\\
$P(E \cap F) = P(E)P(F)$
\subsection{Random Sampling}
Rejection Sampling: Given a uniform distribution, rejection sampling only takes samples if they're within some region of the distribution\\

\textbf{Example:} Simulating a die with a coin\\
Here, we'll flip a coin 3 times, giving us 8 potential outcomes. We'll assign 6 outcomes to a side on the die, then reject two outcomes. If we get our rejected outcomes, we will reflip the coin 3 times.\\
\label{sec:rsampling}
\subsection{Random Variables}
\label{sec:rvariables}
A random variable $X$ assigns a real number to each possible outcome of an experiment ($X: S \rightarrow \mathbb{R})$\\
The distribution of a random variable $X$ is the function $r \rightarrow P(X=r)$
\subsection{Expectation}
\label{sec:expectation}
The expectation (weighted average/ average expected value) of a random variable $X$ on a sample space S is $E(X) = \sum_{s \in S}P(s)X(s)$
\textbf{Example:} What is the expectation of rolling two dice where $X$ is the sum of the value on each die?\\
$E(x) = 2(\frac{1}{36}) + 3(\frac{1}{18}) + 4(\frac{1}{12}) + 5(\frac{1}{9}) + 6(\frac{5}{36}) + 7(\frac{1}{6}) + 8(\frac{5}{36}) + 9(\frac{1}{9}) + 10(\frac{1}{12}) + 11(\frac{1}{18}) + 12(\frac{1}{36}) = 7$
\newpage
\subsubsection{Linearity of Expectation}
\label{sec:lexpectation}
\textbf{Law of Total Expectation:} We can split up the expectation of a random variable into the expectation over a partition of the subspace.\\
\textbf{Indicator Functions}: Useful tool for calculating expectation with law of total expectation. It is defined in the following way:\\
$X_i = \begin{cases}
    1 & \textbf{event occurs}\\
    0 & \textbf{otherwise}
\end{cases}$\\
\textbf{Example:} Suppose 10 dancers select their dresses in a non-uniform way. First, five dancers are randomly picked, and the order in which they're picked determines their color (red is always first, polka-dot second, etc...). The last 5 dancers have their dress color uniformly sampled. What is the expected number of patterns that are only worn by one dancer?\\
Let X represent the number of patterns worn only once, E(X) the expected number of patterns worn only once, and $X_i$ be an indicator variable representing if a dress is worn once.\\
$X_i = \begin{cases}
    1 & \textbf{If pattern is worn only once}\\
    0 & \textbf{otherwise}
\end{cases}$\\
Then,\\
$E(x) = \sum_{i=1}^5(E(X_i))=\\
\sum_{i=1}^5(P(X_i=1)1)=\\
\sum_{i=1}^5((\frac{4}{5}^5)(1))\\
\approx 1.64$]\newpage
\subsection{Variance}
\label{sec:variance}
\textbf{Unexpectedness}:
$U=|X-E|$, where $X$ is random variable and $E$ is expected value\\
\textbf{Average unexpectedness:}
$AU(X) = E(|X-E|)=E(U)$\\
\textbf{Variance:}
$V(X)=E(|X-E|^2)=E(U^2)$\\
\textbf{Standard deviation:}
$\sigma(X)=(E(|X-E|^2))^{\frac{1}{2}}=V(X)^{\frac{1}{2}}$\\
If $X$ and $Y$ are independent, then $V(X+Y)=V(X)+V(Y)$\\
\textbf{Example:} Let you and your friend be equally good at tennis, so that you both have a $\frac{1}{2}$ chance of winning. Let $X_n$ be the win differential. Calculate $E(X_n)$ and the variance of $X_n$:\\
\begin{itemize}
    \item The expected value is 0. Take for example the win differential after one game. It can either be $-1$ or $1$, so the differential is 0. After 2 games, it can either be $2$, $0$, or $-2$. This can be shown more rigorously with the equation $X_n = \sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i)) = 0$\\
    \item The variance is n. As the number of matches goes up, the random variable can vary from the mean by n because either player can have a win differential of $n$ or $-n$. We can show this rigorously:
    $V(X) =
    E(X^2)-(E(X))^2=
    \sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i))^2 - (\sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i)))^2=n$
\end{itemize}

\section{Runtime Analysis}
\label{sec:runtime}
\subsection{Min Sort}
\label{sec:minsort}
Given a list, we start by search iterate over the list starting from the first element to find the lowest value which is then swapped with the first element. We then find the lowest value starting from the second index and swap the second lowest value with second element. We continue this patter of finding the lowest value up to the $n-1$ element where $n$ is the number of elements.\\
\begin{tabular}{c c|c|c|c}
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & {\color{red}5} & {\color{red}3} & {\color{red}2} & {\color{red}4} \\
     & {\color{green}2} & {\color{red}3} & {\color{red}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{red}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{red}5}\\
      & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{green}5}\\
\end{tabular}
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ (ordered elements) & $n-1$ (cyclically shift ordered elements) \\
    comparisons & $\frac{n(n-1)}{2}$ &  $\frac{n(n-1)}{2}$
\end{tabular}
\subsection{Bubble Sort}
\label{sec:bubblesort}
Start at the first two elements and swap them if they are out of order. Continue with the second and third element, etc... until we are at the end of the list. Repeat this process from the beginning, reducing the index where we stop each time (every run through the list sorts the ending elements).\\
\begin{tabular}{c c|c|c|c}
    Run 1:\\
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & 5 & 3 & 2 & 4 \\
    & 3 & 5 & 2 & 4 \\
    & 3 & 2 & 5 & 4 \\
    & 3 & 2 & 4 & 5 \\
    Run 2:\\
    & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    & 3 & 2 & 4 & \color{green}{5} \\
    & 2 & 3 & 4 & \color{green}{5} \\
    & 2 & 3 & 4 & \color{green}{5} \\
\end{tabular}\\
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ & $\frac{n(n-1)}{2}$ \\
    comparisons & $n-1$ &  $\frac{n(n-1)}{2}$
\end{tabular}

\subsection{Insertion Sort}
\label{sec:insertionsort}
Given a list, we start with the second element and move it left until it is in order. We do this for each element up to the last, and the indices before the element that is being moved are considered to be in sorted order.\\
\begin{tabular}{c c|c|c|c}
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & {\color{red}5} & {\color{red}3} & {\color{red}2} & {\color{red}4} \\
     & {\color{green}3} & {\color{green}5} & {\color{red}2} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{green}5}\\
\end{tabular}
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ (ordered elements) & $\frac{n(n-1)}{2}$ (reverse order elements)\\
    comparisons & $n-1$ &  $\frac{n(n-1)}{2}$
\end{tabular}
\newpage
\subsection{Linear Search}
\label{sec:linearsearch}
Iterate over a list from the first element until item is found. If at the end of the list and item wasn't found, then the item isn't contained in the list.\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    comparisons & $1$ (item at front) &  $n$ (item at end or not present)
\end{tabular}
\subsection{Binary Search}
\label{sec:binarysearch}
Binary search uses three positional arguments, hi, lo, and mid, and narrows down the search region every iteration to find an element in a sorted list. For example, given a list of size n, lo and hi will be 0 and 5 respectively on first iteration, and thus mid will be 2. If the item at mid is greater than the element to search for, mid becomes hi, otherwise mid becomes lo, and the process continues.\\
\textbf{Example}: Finding 3 in $[1,3,4,5,6]$:\\
\begin{tabular}{c|c|c|c|c}
     \color{red}{1} & 3 & \color{green}{4} & 5 & \color{blue}{6} \\
     \color{red}{1} & \color{green}{3} & \color{blue}{4} & 5 & 6 
\end{tabular}\\
After the second iteration, the element is found\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    comparisons & $1$ (item at middle) &  $\lceil{\log_{2}(n+1)}$ (item at ends or not present)
\end{tabular}
\subsection{Asymptotic Classes}
\label{sec:asymptotic}
\subsubsection{Big Theta}
\label{sec:theta}
\textbf{Definition}: $f(n) \in \Theta(g(n))$ if there are constants $C, C', \text{ and } k$ such that $f(n) \leq Cg(n)$ and $g(n) \leq C'f(n)$ for all $n \geq k$. In other words, Big $\Theta$ defines a tightly bound relationship (grows just as fast).\\
\textbf{Limit definition}: $f(n) \in \theta(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c$ is finite and $c \neq 0$
\subsubsection{Big Omega}
\label{sec:omega}
\textbf{Definition}: $f(n) \in \Omega(g(n))$ if there are constants $C \text{ and } k$ such that $f(n) \geq Cg(n)$ for all $n \geq k$. In other words, Big $\Omega$ defines a lower bound relationship.\\
\textbf{Limit definition}: $f(n) \in \Omega(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c > 0$ or $c = \infty$
\subsubsection{Little O}
\label{sec:littleo}
\textbf{Definition}: if $g(n)$ grows strictly faster than $f(n)$, then $f(n) \in o(g(n))$. Put another way, $f(n) \in o(g(n))$ and $f(n) \notin o(g(n)) $\\
\textbf{Limit definition}: $f(n) \in o(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = 0$
\subsubsection{Big O}
\label{sec:bigo}
\textbf{Definition}: $f(n) \in O(g(n))$ if there are constants $C \text{ and }k$ such that $f(n) \leq Cg(n)$ for all $n \geq k$. In other words, $g(n)$ grows just as fast or faster than $f(n)$.\\
\textbf{Limit definition}: $f(n) \in O(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c$ is finite\\
\textbf{Examples}:\\
\begin{itemize}
    \item $2^n \in O(n^2)$\\
    $\lim_(n \rightarrow \infty)\frac{2^n}{n^2} =$ (Apply L'Hopital's rule) \\
    $\lim_(n \rightarrow \infty)\frac{2^n\ln{2}}{2n}$ (Apply L'Hopitals rule\\
    $\lim_(n \rightarrow \infty)\frac{2^n\ln{2}^2}{2} = \infty$ \\
    Thus, the statement is false.
    \item $F_n \in O(2^n)$ where $F_n$ is a function representing the fibonacci sequence.\\
    $F_n = F_{n-1} + F_{n-2}, F_0=1, F_1=1$\\
    Claim: $F_n \leq 2^n$ for all $n \geq 0$\\
    Base cases:\\
    $F_0=1,2^0=1$\\
    $F_1=1, 2^1=2$\\
    Induction step:\\
    Let $k$ be an arbitrary integer such that $k > 1$. \\
    Assume that $F_m \leq 2^m$ for all m in the range $0 \leq m \leq k$.\\
    WTS $F_k \leq 2^k$:\\
    $F_k=F_{k-1}+F_{k-2} \leq 2^{k-1}+2^{k-2} = 2^{k-2}(2+1) \leq 2^{k-2}(4) = 2^k$\\
    Thus, the statement is true.
    
\end{itemize}
\subsubsection{Big O Class Properties}
\label{sec:oproperties}
\textbf{Domination}: If $f(n) \leq g(n)$ for all $n$ then $f(n) \in O(g(n))$\\
\textbf{Transitivity}: If $f(n) \in O(g(n))$ and $g(n) \in O(h(n))$ then $f(n) \in O(h(n))$\\
\textbf{Additivity/ Multiplicativity}: If $f(n) \in O(g(n))$ and $h(n)$ is non-negative then\\ $f(n)+h(n) \in O(g(n)+h(n))$ and $f(n) \cdot h(n) \in O(g(n) \cdot h(n))$\\
\textbf{Sum is maximum}: $f(n) + g(n) \in O(\text{max}\{f(n),g(n)\})$\\
\textbf{Ignoring constants}: For any constant $c$, $c \cdot f(n) \in O(f(n))$
\subsubsection{Growth Rate of Common Functions}
\label{sec:functions}
\scalebox{0.75}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
     1 (fastest) & $\log(\log n)$ & $\log n$ & $(\log n)^k$ & $n$ & $n\log n$ & $n^k$ & $a^n$ & $n!$ & $n^n$ (slowest)\\
     \hline
     constant & double-logarithm & logarithm & poly-logarithm & linear & log-linear & polynomial & exponential & factorial & 
\end{tabular}
}
\subsubsection{Disjoint Lists Function}
\label{sec:disjoint}
Given two sorted lists, $a[1], \dots, a[n]$ and $b[1] , \dots, b[n]$, determine if they are disjoint or not.\\
Method 1:\\
$\text{for i in } 1 \dots n$\\
$\hspace*{1cm} \text{if }\textbf{BinarySearch}((b[1], \dots, b[n]), a[i]) \neq 0$\\
$\hspace*{2cm} \textbf{return }\text{false;}$\\
$\hspace*{1cm} \textbf{return }\text{true;}$\\
Takes $O(nlogn)$ time.\\
Faster ways: Hashmap, double while loop that we implement\\
Method 2, double while loop:\\
$\text{i=1}\\
\text{j=1}\\
\textbf{while }i < n\\
\hspace*{1cm}\textbf{while }j < n\\
\hspace*{2cm}\textbf{if }a[i] = b[j]\textbf{ then}\\
\hspace*{3cm}\textbf{return}\text{ FALSE}\\
\hspace*{2cm} \textbf{else} \\
\hspace*{3cm}\textbf{if } a[i] < b[j]\textbf{ then}\\
\hspace*{4cm} i = i +1\\
\hspace*{3cm}\textbf{if } a[i] > b[j]\textbf{ then}\\
\hspace*{4cm} i = j + 1 \\
\textbf{return}\text{ TRUE}$
\subsection{Product Rule}
\label{sec:rproduct}
If the inner loop runs $O(T_1(n))$ and the outer loop runs $O(T_2(n))$, worst case runtime is $O(T_1(n)T_2(n))$. Note, this is not always a tight bound (total time could be much faster).\\

\subsection{Loop Invariant Induction}
\label{sec:invariant}
 \textbf{Loop Invariant}: A property that remains true after each time the body of a loop is executed.\\
 \textbf{3 Step Plan for iterative algorithm}
 \begin{enumerate}
     \item Look for a loop invariant
     \item Prove that it is an invariant
     \item Use invariant to prove correctness
 \end{enumerate}
 \subsubsection{Selection Sort Loop Invariant Induction}
 \label{sec:selectionsortproof}
 \textbf{Loop Invariant}: After $t$ iterations, the first $t$ elements are in sorted order and the first $t$ elements are the smallest.\\
 \textbf{Base Case}: $(t=0)$ After $0$ iterations,
 \begin{itemize}
     \item The first $0$ elements are in sorted ordered (vacuously true)
     \item The first $0$ elemets are the smalles (vacuously true)
 \end{itemize}
 \textbf{Inductive Hypothesis}: Suppose that for some $t \geq 0$, the loop invariant is true after $t$ iterations.\\
 \textbf{WTS}: The inductive hypothesis is true after $t+1$ iterations\\
 During the $(t+1)$th iteration, the algorithm sets $a_m$ to be the minimum value of $a_{t+1},\dots,a_n$, and $a_m$ is then swapped with $a_{t+1}$. So after the $(t+1)$th iteration, $a_{t+1}$ is the minimum value of $a_{t+1},\dots,a_n$.\\
 By the inductive hypothesis, $a_1,\dots,a_t$ are in sorted order and are the smallest $t$ elements. Therefore we have that $a_1,\dots,a_t$ are all less than $a_{t+1}$ and $a_{t+1}$ is less than all of $a_{t+1},\dots,a_n$, so $a_1,\dots,a_{t+1}$ are the smallest $(t+1)$ elements of the original list. Additionally, we have that $a_1,\dots,a_t$ are all in sorted order and since $a_1,\dots,a_t$ are all less than $a_{t+1}$, $a_1,\dots,a_{t+1}$ are all in sorted order.
 \subsubsection{Find Max Loop Invariant Induction}
\label{sec:findmaxproof}
 \textbf{Invariant}: After each iteration, max is the maximum value of the list $(a[1], a[2])(i=2)$.\\
 Proof:\\
 \textbf{Base case}: After 0 iterations, max is maximum $(a[1])$. After one iteration, max is the maximum of $(a[1], a[2]) \ (i=2)$\\
 Let $t \geq 1$ be an arbitrary integer.\\
 Assume that after t iterations, max is a maximum of $(a_1,\dots, a_t)$.\\
 Let $i'=i+1$. \textbf{WTS} after t+1 iterations, max is a maximum of $(a_1,\dots, a_{i'})$.\\
 During the t+1 iteration, $i'=i+1$. There are two cases to consider:\\
Case 1: $a_i' > \text{max}$. max is maximum of $a_1,\dots,a_i$. Thus, the maximum is $a_i'$, and max updates to be $a_i'$. Therefore, max is a maximum of $(a_1,\dots, a_{i'}$.\\
Case 2: $a_i' < \text{max}$. max is maximum of $a_1,\dots,a_i$ and max never updates. Therefore, max is a maximum of $(a_1,\dots, a_{i'}$.\\
\section{Recursion}
\label{sec:recursion}
\subsection{Recursive find max proof}
\label{sec:rfindmaxproof}
\textbf{Findmaxrec}(a[1…n] array of distinct integers)\\
$\hspace*{0.5cm}$if n == 1 then return a[1]\\
$\hspace*{0.5cm}$M1 = Findmaxrec(a[1,…n-1])\\
$\hspace*{0.5cm}$return MAXIMUM(M1,a[n])\\
\textbf{Proof}\\
\textbf{Base Case:} $n=1$, the list has one element $a[1]$ and the one element is the maximum of the list.\\
\textbf{Inductive Hypothesis:} Let $k$ be an arbitrary integer such that $k > 1$. Assume that Findmaxrec is correct on all inputs of length $k-1$.\\
\textbf{Inductive Step:} $M1$ is set to Findmaxrec(a[1], ... ,a[k-1]), and by the inductive hypothesis, $M1$ is the max of a[1], ... a[k-1]. The maximum of a[1],...,a[k] is the maximum of $M1$ and a[k] which is what the algorithm returns.

\subsection{Merge sort (divide and conquer)}
\label{sec:mergesort}
\textbf{Algorithm}\\
$\text{Rmerge}([a_1,\dots,a_k],[b_1,\dots,b_l])\\
\textbf{if } k == 0 \textbf{ then return } [b_1,\dots,b_l]\\
\textbf{if } k == 0 \textbf{ then return } [a_1,\dots,a_k]\\
\textbf{if } a_1 < b_1 \textbf{then:}\\
\hspace*{0.5cm} \text{return } a_1 \cdot \text{ Rmerge}([a_2,\dots,a_k],[b_1,\dots,b_l])\\
\textbf{else}\\
\hspace*{0.5cm} \text{return } a_1 \cdot \text{ Rmerge}([a_1,\dots,a_k],[b_2,\dots,b_l])$
Recursive Proof:\\
Proof by strong induction:\\
Base case: $n=0$. Then, return the empty list (trivially sorted)\\
Suppose $n=1$. Then return $a_1$, a trivially sorted list containing all elements\\
Induction step: Suppose $n>1$. Assume, as the strong induction hypothesis, that\\
$\hspace*{0.5cm}\text{MergeSort correctly sorts all lists with k elements for any } 0 \leq k < n$
WTS: prove that MergeSort($a_1,\dots,a_n$) returns a sorted list containing all n elements for any arbitrary list $a_1,\dots,a_n$\\
$ m = \left\lfloor \frac{n}{2} \right\rfloor $ (Note that $0 \leq m < n$)\\
$L_1 = \text{MergeSort}(a_1,\dots,a_m)$ ($m < n$) so $L_1$ is a sorted list of these elements (By IH)\\
$L_2 = \text{MergeSort}(a_{m+1},\dots,a_n)$ so $L_2$ is a sorted list of these elements (By IH)\\
By the correctness of RMerge, RMerge($L_1,L_2$) is a sorted list of all elements.\\
\textbf{Recurrece relation:}\\
$\text{Rmerge}([a_1,\dots,a_k],[b_1,\dots,b_l]) \text{ T(n)}\\
\textbf{if } k == 0 \textbf{ then return } [b_1,\dots,b_l] \text{ O(1)}\\
\textbf{if } k == 0 \textbf{ then return } [a_1,\dots,a_k] \text{ O(1)}\\
\textbf{if } a_1 < b_1 \textbf{then:} \text{ O(1)}\\
\hspace*{0.5cm} \text{return } a_1 \cdot \text{ Rmerge}([a_2,\dots,a_k],[b_1,\dots,b_l]) \text{ T(}\frac{n}{2}\text{)}\\
\textbf{else}\\
\hspace*{0.5cm} \text{return } a_1 \cdot \text{ Rmerge}([a_1,\dots,a_k],[b_2,\dots,b_l]) \text{ T(}\frac{n}{2}\text{)}$\\
$T(n)=2T(\frac{n}{2})+O(n)$\\
\textbf{Solving recurrence relation}\\
\text{Unravelling:}\\
$T(n)=2T(\frac{n}{2})+cn$\\
$T(n)=2(2T(\frac{n}{2^2})+c(\frac{n}{2}))+cn$\\
$T(n)=2^2T(\frac{n}{2^2})+cn+cn$\\
$T(n)=2^2(2T(\frac{n}{2^3})+c(\frac{n}{2^3}))+cn+cn$\\
$T(n)=2^3T(\frac{n}{2^3})+cn+cn+cn$\\
$T(n)=2^kT(\frac{n}{2^k})+kcn$\\
$\vdots$\\
$\log_2nT(n)=2^{\log_2n}T(\frac{n}{2^{\log_2n}}+(\log_2n)\cdot c \cdot n = nT(1)+cn\log_2n = c_1n + cn\log_2n$

\subsection{Master theorem}
\label{sec:master}
$T(n) = aT(\frac{n}{b}) + O(n^d)$
\begin{itemize}
    \item \textbf{a}: The number of recursive calls
    \item \textbf{b}: Fraction of the original input size of recursive calls
    \item \textbf{d}: Degree of polynomial of the number of non recursive part
\end{itemize}
\begin{tabular}{c|c}
\hline
    $O(n^d)$ &  if $a < b^d$\\
    $O(n^dlogn$ & if $a = b^d$\\
    $O(n^{log_ba}$ & if $a > b^d$\\
\end{tabular}
\subsubsection{Mergesort}
Alternative way of solving recurrence relation (original way is unravelling)\\
Recurrence relation: $T(n)=2T(\frac{n}{2})+O(n)$\\
$a=2,b=2,d=1$. Therefore, $a=b^d$, and the recurrence relation is $O(n^1\log n)$
\subsection{Homogeneous Recurrence Relations}
\label{sec:homogenous}
\subsubsection{Domino Tilings}
\label{sec:domino}
How many ways can we fill a 2 by $n$ grid with dominos? (Domino can either be vertical or horizontal)\\
$DT(n)$ is the number of different domino tilinigs of a 2 by $n$ grid\\
$DT(n) = DT(n-1) + DT(n-2)$ for $n > 2$ $DT(n-1)$ represents placing a domino vertical in first column, and $DT(n-2)$ represents placing placing two horizontally stacked dominos in the first two columns. The base cases are $DT(1)=1$ and $DT(2)=2$.
\subsubsection{Characteristic Polynomial}
\label{sec:characteristic}
Guess the polynomial: $DT(n)=Ar^n$\\
Eliminate:\\
If recurrence relation is $DT(n) = DT(n-1)+DT(n-2)$, we replace the recurring terms with a polynomial such that $Ar^n=Ar^{n-1}+Ar^{n-2}$, then simplify so that it become $r^2=r+1$\\
Solve the roots:\\
In this case, the roots are $\frac{1 \pm \sqrt{5}}{2}$.\\
Write a characteristic polynomial:\\
We can rewrite the recurrence relation as $DT(n)=A_1x_1^{n}+\dots+A_kx_k^{n}$ when the polynomial has k roots.
\subsubsection{Fibonacci}
\label{sec:fibonacci}
Fibonacci sequence: 1,1,2,3,5,8,13,21,...\\
$Fib(n) = Fib(n-1) + Fib(n-2)$ for all $n>2$ where $Fib(1)=1$ and $Fib(2)=2$
\subsection{Recursive Counting}
\label{sec:rcounting}
\subsubsection{Permutations/Stirling's Approximation}
\label{sec:stirling}
\textbf{Stirling's Approximation}
$n! \approx (\frac{n}{e})^n\sqrt{2 \pi n}$ (nearest integer)\\
\textbf{Permutations}
$S(n)=n \cdot S(n-1) = n!$\\
Approximate with stirling's approximation

\subsubsection{n-bit strings}
\label{sec:nstring}
\textbf{Avoid the substring 11}\\
List out substrings:
\begin{enumerate}
    \item A(0) = 1
    \item A(1) = 2
    \item A(2) = 3
    \item A(3) = 5
\end{enumerate}
$A(n)$ = number of n-bit 11-avoiders starting with 0 + number of n-bit 11-avoiders starting with 1\\
$A(n) = A(n-1) + A(n-2)$\\
$A(0) = 1, A(1) = 2$
Devolves into fibonacci.\\
\textbf{Avoid the substring 111}\\
$B(n)=B(n-1)+B(n-2)+B(n-3)$ where $B(0)=0$, $B(1)=2$, and $B(2)=4$

\subsubsection{Solving Recurrences}
\label{sec:solver}
\begin{enumerate}
    \item \textbf{Guess and Check}: Start with small values of n and look for a pattern. Confirm guess and check with proof by induction.
    \item \textbf{Unravel}: Start with the general recurrence and keep replacing n with smaller input values. Keep unraveling until you reach the base case.
    \item \textbf{Characteristic Polynomial}: If the recursion is of a certain form, you can guess that the closed form is $Cw^n$ and solve for $w$ by finding the root of the polynomial. (Note: better for finding a bound rather than closed form)
\end{enumerate}

\section{Encoding}
\label{sec:encoding}
\subsection{Lossy vs. Lossless encoding}
\textbf{Lossy encoding:} Some of the data is lost in tge encoding process.\\
\textbf{Lossless econding:} The data can be restored to its original state without any losses. 
\label{sec:loss}
\subsection{Fixed-width encoding}
First determine the number of bits we need to encode all symbols in the alphabet by calculating $ \left \lceil \log_2 n \right \rceil $, where n is the number of symbols in the alphabet. Then,  assign binary numbers to each character with the number of bits we have. We can then construct new strings with these binary numbers. \\
\label{sec:fwencode}
\newpage
\subsection{Huffman encoding}
\label{sec:huffman}
type of variable length encoding where symbols that appear more frequent are represented by shorter length encodings.\\
\textbf{Building Huffman Tree}\\
Group together the two lowest frequencies and break ties by using alphabetical order left to right.\\
\begin{center}
\includegraphics[scale=0.4]{HuffmanTree.png}\\
\end{center}
\subsection{Fibonacci Encoding}
\label{sec:fibencode}
\textbf{Zeckendorf's Theorem:} Each positive integer can uniquely be represented as the sum of non-consecutive Fibonacci numbers.
\begin{itemize}
    \item We can represent a sequence of positive integers with binary strings that use two ones in a row to signal the start of a new integer.\\
\end{itemize}
\textbf{Example:} We want to encode (2,5,24,15,1) which is $011 00011 00100011 0100011 11$\\
\begin{tabular}{c|c|c|c|c|c|c|c}
    n & 1 & 2 & 3 & 5 & 8 & 13 & 21 \\
    \hline
    2 & 0 & 1 & & & & &\\
    5 & 0 & 0 & 0 & 1 & & &\\
    24& 0 & 0 & 1 & 0 & 0 & 0 & 1\\
    15& 0 & 1 & 0 & 0 & 0 & 1 &\\
    1 & 1 & & & & & &\\
\end{tabular}
\newpage
\subsection{Ranking and Unranking}
\label{sec:ranking}
Ranking:\\
For each 1 in the binary string, calculate the sum of binomials $\binom{n}{k}$, where $n$ is each 1's position and $k$ is the order of the 1 (going left to right).\\
Unranking:\\
Convert the binary string into a number, $r$. Then, start from the highest position, $k$. Find the greatest $n$ such that $\binom{n}{k} \leq r$. Then subtract this value from $r$ to net a new $r$. Repeat until $r$ is $0$.\\
\subsection{Optimal length encoding}
\label{sec:optimal}
The optimal length encoding is $\left \lceil \log_2 n \right \rceil$, where n is the total number of unique strings. This encoding can be achieved with a dictionary, or with special algorithms.\\

\section{Graph Theory}
\label{sec:graphtheory}
\subsection{Graphs}
\label{sec:graphs}
\subsubsection{Directed Graphs}
\label{sec:directed}
\begin{spacing}{1.0}
\begin{itemize}
    \item Edges have a direction
    \item $n(n-1)$ potential edges on $n$ vertices
    \item $2^{n(n-1)}$ different directed graphs on $n$ vertices
    \item InDegree is the number of edges going to vertex
    \item OutDegree is the number of edges going from vertex
    \item A directed graph is strongly connected if for any ordered pair of vertices $(v,w)$, there is a directed path from $v$ to $w$
    \item A directed graph is weakly connected if the arrows are removed and the resulting undirected graph is connected
\end{itemize}
\subsubsection{Directed Acyclic Graph (DAG)}
\label{sec:directedac}
\textbf{Directed acyclic graph:} directed graph with no cycles.\\
\textbf{Sources:} Vertices with no incoming edges
\textbf{Sinks: } Vertices with no outgoing edges
\textbf{Topological ordering/linearization:} An ordered list of all of a graphs' vertices such that for each directed edge (v,w) in the list, v comes before w.
\end{spacing}
\newpage
\subsubsection{Undirected graphs}
\label{sec:undirected}
\begin{spacing}{1}
\begin{itemize}
    \item Edges don't have direction
    \item $\binom{n}{2}$ potential edges on $n$ vertices
    \item $2^{\binom{n}{2}}$ different simple undirected graphs on $n$ vertices
    \item Degree of vertex is the total number of edges incident with it (self-loop contributes twice)
    \item $2 \cdot E = s$ where $E$ is the number of edges and $s$ is the sum of degrees
    \item A undirected graph is connected if for any pair of vertices $(v,w)$ there is a path from $v$ to $w$
\end{itemize}
\end{spacing}
\subsubsection{Connectedness}
\label{sec:connectedness}
\begin{itemize}
    \item Connected graph:
    A graph is connected if for any pair of vertices, v and w, there is a path between them.
    \item Weakly connected graph:
    A graph is weakly connected when if you remove all the arrows, the resulting graph is connected.
    \item Strongly connected graph:
    A graph is strongly connected if there is a directed path between any pair of vertices, v and w.
    \item Connected components:
    A connected component is a subsection of a graph that is connected.
    \item Bipartite graphs:
    A bipartite graph is when all the vertices can be arranged into two groups such that two vertices in the same group are not connected by an edge.
    \item Complete graphs:
    A complete graph is an undirected graph such that there is an edge between any two vertices.
\end{itemize}
\subsection{Hamiltonian paths}
\label{sec:hamilton}
Hamiltonian paths visit every vertex exactly once.\\
\textbf{Example}\\
DNA reconstruction where we have $N$ 3-character DNA strings and we want to find the shortest possible length  DNA string that includes them all ($N+2$). We can solve this by considering the 2 characters that the strings can share. We can create a hamiltonian path by defining the vertex set as each DNA string, and the edge set as the edge from $v$ to $w$ where the first 2 characters of $w$ match the last 2 characters of $v$.  
\newpage
\subsection{Eulerian paths}
\label{sec:eulerian}
Eulerian paths visit every edge exactly once.\\
If $G$ is an undirected path and has an Eulerian trail, $G$ has at most two odd-degree vertices\\
\textbf{Example}\\
Based on the example with DNA strings in the previous section, we can use a eulerian path by defining the vertex set as all length-two strings that appear and the edge set as an edge from ab to bc such that abc is in the set of strings.\\
\textbf{Fleury's algorithm:}
\begin{spacing}{1}
    \begin{itemize}
        \item Start at vertex $v$ with odd-degree if possible
        \item Continue to cross any edge that is not a bridge
    \end{itemize}
\end{spacing}
\begin{center}
   \includegraphics[scale=0.3]{Eulerian.png} 
\end{center}
\subsection{Adjacency matrix}
Matrix which encodes the connections between two vertices. In directed graphs, the connections between two vertices are not recorded twice. Self loops are recorded along the main diagonal. For directed graphs, the number of parallel edges are specified, not just a 1 or 0 denoting the connection
\newpage
\subsection{Trees}
\label{sec:trees}
\textbf{Types}
\begin{itemize}
    \item Binary tree: each node has at most 2 children
    \item Complete binary tree: a binary tree in which every level, except possibly the last, is completely filled and all nodes on the last level are as far left as possible
    \item Full binary tree: a binary tree where every node has 0 or 2 children
    \item Unrooted tree: An undirected graph if it is connected and has no cycles
    \begin{itemize}
        \item Leaves in tree have vertices of degree $1$
        \item All trees with $n$ vertices have $n-1$ edges
        \item A set of trees is called a forest
        \item 1 simple path between each pair of vertices
    \end{itemize}
    \item Binary Search Tree: For each node, every node in the left sub-bst has a smaller value than the node and every node in the right sub-bst has a greater value that the node. $O(logn)$ for searching, insertings, and deleting.
    \item Decision Tree: binary tree that uniquely characterizes elements of a set based on the answers to yes or no questions.
\end{itemize}
\textbf{Runtime}\\
\begin{tabular}{c|c|c|c}
     operation & best case & average case & worst case \\
     search & $O(1) $ & $O(\log n)$ & $O(n)$ \\
     insert & $O(1) $ & $O(\log n)$ & $O(n)$ \\
     delete & $O(1) $ & $O(\log n)$ & $O(n)$ \\
\end{tabular}\\
\textbf{Worst case is only possible with unbalanced tree}\\
\newpage
\section{Randomized Algorithms}
\label{sec:randalgo}
\textbf{Deterministic Algorithms:} Generate an output based on a determined set of rules and always work exactly the same on the same input.\\
\textbf{Random Algorithms:} Generate an output based on a source of random numbers and determined set of rules. May work differently on the same input.\\
\subsection{Las Vegas Algorithms}
\label{sec:vegas}
\begin{itemize}
    \item Always returns correct answer
    \item Runtime varies
\end{itemize}
\textbf{Example: QuickSort}\\
Quicksort\\
Like merge sort, but chooses pivot instead of dividing into 2. As opposed to mergesort, quicksort is an in-place sorting algorithm. Below is the general algorithm.\\
\begin{spacing}{1}
\begin{itemize}
    \item Start with middle index as pivot and swap data so values greater than pivot are on the right and values left of the pivot are on the left\\
    \item Partition function to move values around pivot\\
    \item Start with lowindex and increment until number at lowindex is greater than pivot\\
    \item Start with highindex and decrement until number at highindex is less than pivot\\
    \item If lowindex is greater than highindex, then partition is done\\
    \item Otherwise swap lowindex and highindex and shift indexes by one and return high index\\
    \item Quicksort the left portion and right portion again recursively (low index to high index, high index + 1to n)\\
\end{itemize}
\end{spacing}
\textbf{Runtime}\\
Best case: $O(n \log n)$\\
Worst case: $O(n^2)$\\
While quicksort always returns the list in the correct, sorted order, because its runtime varies, it is a Las Vegas Algorithm.\\

\subsection{Monte Carlo Algorithms}
\label{sec:montecarlo}
\begin{itemize}
    \item Not always correct
    \item Runtime is consistent
\end{itemize}
\end{spacing}
\end{document}
