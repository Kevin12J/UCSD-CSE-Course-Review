\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{setspace}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{mathtools}

\title{UCSD CSE 21 Review}
\author{Taanish Reja and Kevin Jacob}
\date{Spring 2024}

\begin{document}
\begin{spacing}{1.5}
\maketitle
\newpage

\section*{Table of Contents}

\begin{enumerate}
%Counting Contents
\item \hyperref[sec:counting]{Counting}
\begin{itemize}
\item \hyperref[sec:sets]{Sets}
\begin{itemize}
\item \hyperref[sec:multiset]{Multiset}
\item \hyperref[sec:subset]{Subset}
\end{itemize}
\item \hyperref[sec:product]{Product Rule}
\item \hyperref[sec:sum]{Sum Rule}
\item \hyperref[sec:power]{Power Rule}
\item \hyperref[sec:quotient]{Quotient Rule}
\item \hyperref[sec:inclusionexclusion]{Inclusion Exclusion Principle}
\item \hyperref[sec:complement]{Counting With Complement}
\item \hyperref[sec:permutations]{Permutations}
\item \hyperref[sec:combinations]{Combinations}
\item \hyperref[sec:binomial]{Binomial Coefficients}
\begin{itemize}
    \item \hyperref[sec:symmetry]{Symmetry Identity}
    \item \hyperref[sec:btheorem]{Binomial Theorem}
    \item \hyperref[sec:pascal]{Pascal's Identity}
    \item \hyperref[sec:sidentity]{Sum Identity}
\end{itemize}
\item \hyperref[sec:starsbars]{Stars and Bars}
\item \hyperref[sec:12fold]{The 12-fold way}
\end{itemize}
\newpage
\item \hyperref[sec:probability]{Distributions and Probability}
\begin{itemize}
    \item \hyperref[sec:pbasics]{Probability Basics}
    \item \hyperref[sec:uniform]{Uniform/Non-Uniform distributions}
    \item \hyperref[sec:binomial_distribution]{Binomial Distribution}
    \item \hyperref[sec:conditional]{Conditional Probability}
    \item \hyperref[sec:bayes]{Bayes Theorem}
    \item \hyperref[sec:independence]{Independence}
    \item \hyperref[sec:rsampling]{Random Sampling}
    \item \hyperref[sec:rvariables]{Random variables}
    \item \hyperref[sec:expectation]{Expectation}
    \begin{itemize}
        \item \hyperref[sec:lexpectation]{Linearity of Expectation}
    \end{itemize}
    \item \hyperref[sec:variance]{Variance}
\end{itemize}
\item \hyperref[sec:runtime]{Runtime Analysis{}}
\begin{itemize}
    \item \hyperref[sec:minsort]{Min Sort}
    \item \hyperref[sec:bubblesort]{Bubble Sort}
    \item \hyperref[sec:insertionsort]{Insertion Sort}
    \item \hyperref[sec:linearsearch]{Linear Search}
    \item \hyperref[sec:binarysearch]{Binary Search}
    \item \hyperref[sec:asymptotic]{Asymptotic Classes}
    \begin{itemize}
        \item \hyperref[sec:theta]{Big Theta}
        \item \hyperref[sec:omega]{Big Omega}
        \item \hyperref[sec:littleo]{Little O}
        \item \hyperref[sec:bigo]{Big O}
        \item \hyperref[sec:oproperties]{Big O Class Properties}
        \item \hyperref[sec:functions]{Growth Rate of Common Functions}
        \item \hyperref[sec:disjoint]{Disjoint Lists Function}
    \end{itemize}
    \item \hyperref[sec:rproduct]{Product Rule}
    \item \hyperref[sec:invariant]{Loop Invariant Induction}
    \begin{itemize}
        \item \hyperref[sec:selectionsortproof]{Selection Sort Loop Invariant Induction}
        \item \hyperref[sec:findmaxproof]{Find Max Proof}
    \end{itemize}
\end{itemize}
\end{enumerate}
\newpage
%Sets Section
\subsection{Sets}
\label{sec:sets}
%
\subsubsection{Multi-set}
\label{sec:multiset}
A set that allows for repeats ( {1,1,2,3} )\\
\textbf{Anagram:} A string that is a rearrangement of a multi-set of characters\\
\textbf{Example:} How many anagrams of \text{\color{red}{A}\color{green}{EE}\color{blue}{SSSS}\color{orange}{R}}\\
We need to consider over counting since swapping repeated letters will be the same, so the number we over count by is $2! \times 4!$. Therefore the total number of anagrams is $\frac{8!}{2! \times 4!}$.
%
\subsubsection{Subset}
\label{sec:subset}
A set $A$ is a subset of another set $B$ if $B$ contains all the elements in $A$.\\
\textbf{Example:} finding the number of subsets of k elements from set of n elements\\
To find the number of subsets of k elements from set of n elements, we can do $\binom{n}{k}$
%Counting Section
\section{Counting}
\label{sec:counting}
%
\subsection{Product Rule}
For any set, $|A \times B| = |A||B|$\\
$A \times B = \{(a,b): a\in A, b\in B\}$
\label{sec:product}
%
\subsection{Sum Rule}
\label{sec:sum}
For disjoint sets, $A \cap B = \emptyset$, $A \cup B = A + B$
%
\subsection{Power Rule}
\label{sec:power}
For any set, $|A \times A \times A \times \dots \times A| = |A|^{n}$\\
\textbf{Examples:}
\begin{itemize}
    \item $\text{\# of binary strings of length n} = 2^n$
    \item $\text{\# of strings of length n over alphabet } A = |A|^n$
    \item $\text{\# of n-length sequences consisting of elements from sets of the same cardinality} = |A|^{n}$
    \item $\text{\# of ways to distribute $|A|$ distinct objects among $n$ people} = n^{|A|}$
\end{itemize}
%
\subsection{Quotient Rule}
\label{sec:quotient}
If set $A$ can be partitioned into disjoint sets\\
$X_1, X_2, \dots, X_k$, where $|X_1| = |X_2| = \dots = |X_k|$\\
$k= \frac{|A|}{|X_1|}$\\
\textbf{Example with object symmetries:}
\begin{itemize}
    \item Color a square with 4 colors
    \item $4!$ different ways to order/construct quare
    \item 8 object symmetries (4 rotations and 2 reflections)
\end{itemize}
$\text{\# of theoretical objects} = 4! = 24$\\
$\text{\# of physical objects} = \frac{24}{8} = 3$
%
\subsection{Inclusion Exclusion Principle}
\label{sec:inclusionexclusion}
\textbf{For two sets:} $|A \cup B| = |A| + |B| - |A \cap B|$\\
If $A_1, A_2, \dots, A_n$ are finite sets then\\
\textbf{Generalized:}\\ $|A_1 \cup A_2 \cup \dots \cup A_n| =\\ \sum_{1 \leq i \leq n} |A_i| - \sum_{1 \leq i < j \leq n}|A_i \cap A_j| + \sum_{1 \leq i < j < k \leq n}|A_i \cap A_j \cap A_k| - \dots + (-1)^{n+1}|A_1 \cap A_2 \cap \dots \cap A_n|$\\
\textbf{Example with fixed points:}\\
Take the string $1234$. We can set a fixed point, say, at position 1. This means the 1 will be fixed, and that we can form anagrams by shifting the other positions.\\
We want to figure out how many permutations of length 4 have a fixed point at position 1 or 2 or 3 or 4. To do this, we can use inclusion-exclusion. Let $P_i$ represent the number of permutations at each fixed point $i$.\\
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \sum(P_i) - \sum(P_i \cap P_j) + \sum(P_i \cap P_j \cap P_k) - (P_1 \cap P_2 \cap P_3 \cap P_4)$\\
Here, we use permutations because if one spot is fixed, there is 3 spots we can permutate, etc...
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \sum(3!) - \sum(2!) + \sum(1!) - (0!)$\\
Here, we multiply by $\binom{4}{x}$ because if x positions are fixed, $\binom{4}{x}$ gives us the \# of ways to arrange those fixed positions.\\
$|P_1 \cup P_2 \cup P_3 \cup P_4| = \binom{4}{1}(3!) - \binom{4}{2}(2!) + \binom{4}{3}(1!) - \binom{4}{4}(0!)$\\
Fixed points can be generalized with the formula: \\ $n!\sum_{k=1}^n\frac{(-1)^{k+1}}{k!}$\\
\textbf{Derangements}\\
Using our newly defined fixed points formula, as well as \hyperref[sec:complement]{counting with complements}, we can count derangements, or the number of permutations of the string {1,2,\dots,n} without a fixed point.\\

$n! - n!\sum_{k=1}^n\frac{(-1)^{k+1}}{k!}=\sum_{k=1}^n\frac{(-1)^{k}}{k!}$


%
\subsection{Counting With Complement}
\label{sec:complement}
\textbf{Universal Set ($U$):} Set that contains all elements\\
\textbf{Set ($A$):} Subset of the universal set\\
\textbf{Set Complement ($A^c$):} Set that contains all elements in universal set that aren't in $A$\\
$U = A + A^c$ or $A = U - A^c$\\
\textbf{Example:} How many 4 digit strings of digits 0-9 have at least one 0?\\
$U$ = set of all 4 digits strings where $|U| = 10^4$\\
$A^c$ = set of all strings that don't have 0 where $|A^c| = 9^4$\\
$10^4-9^4$ is the number of 4 digit strings that have at least one 0
%
\subsection{Permutations}
\label{sec:permutations}
\textbf{r-permutations:} \# of ways to arrange $r$ objects out of $n$ objects. (Order matters here, whereas in combinations, order doesn't matter)\\
$P(n,r) = {}_nP{}_r = n(n-1)(n-2)\dots(n-r+1) = \frac{n!}{(n-r)!}$\\
\textbf{n-permutations:} rearrangement of $n$ distinct objects so that each object appears exactly once\\
$n!$\\
\textbf{Example with r words over an alphabet of length n}\\
How many 3 letter words can you form from a 10 letter alphabet?\\
$P(10, 3) = \frac{10!}{(10-7)!}$\\
\textbf{Example with different ways athletes can finish in a race}\\
How many ways can 10 athletes finish in a race?\\
$n! = 10!$

% 
\subsection{Combinations}
\label{sec:combinations}
\# of ways to chose $r$ different elements from a set of n distinct elements
$C(n,r) = \frac{P(n,r)}{r!} = \frac{n!}{r!(n-r)!}$\\
\textbf{Example with $\binom{n}{k}$:}
\begin{itemize}
    \item How many k-element subsets of a set of cardinality n
    \item How many length n binary strings with exactly k ones (density = \# of 1 bits = k)
\end{itemize}
%
\subsection{Binomial Coefficients}
\label{sec:binomial}
\textbf{Binomial coefficient}: $\binom{n}{k}$\\
The number of ways to choose k objects out of a set of k. Order doesn't matter, but since it counts sets, two sets cannot have the same elements.
%
\subsubsection{Symmetry Identity}
\label{sec:symmetry}
\textbf{Symmetry Identity:} $\binom{n}{k} = \binom{n}{n-k}$
%
\subsubsection{Binomial Theorem}
\label{sec:btheorem}
$(x+y)^n = (x+y)(x+y) \dots (x+y) = \binom{n}{0}x^n + \binom{n}{1}x^{n-1}y + \binom{n}{2}x^{n-2}y^2 + \dots + \binom{n}{n-1}xy^{n-1} + \binom{n}{n}y^n$\\
Number of ways we can choose $k$ of $n$ factors to contribute to $y$ and $n-k$ factors to contribute to $x$: $\binom{n}{k{z^{n-k}y^k}}$
%
\subsubsection {Pascal's Identity}
\label{sec:pascal}
\textbf{Pascal's Identity} $\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$\\
\textbf{Example:} Combinatorial Proof\\
Consider Pascal's Identity: $\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$. The left hand side counts the number of strings of length $n+1$ with $k$ 1's. Meanwhile, the right hand side counts the number of length $n$ strings with $k$ 1's plus the number of length $n$ strings with $k-1$ 1's. The number of length $n$ strings with $k$ 1's is the same as the number of length $n+1$ strings with a 0 in the first term and $k$ 1's in the last $n$ terms, and the number of length $n$ strings with $k-1$ 1's counts the number of length $n+1$ strings with a 1 in the first term and $k-1$ 1's in the last $n$ terms. Thus, the sum of these terms counts the number of length $n+1$ strings with $k$ 1's. Therefore, the LHS and RHS are the same.
%
\subsubsection {Sum Identity}
\label{sec:sidentity}
$\sum_{k=0}^n \binom{n}{k} = 2^n$
%
\subsection {Stars and Bars}
\label{sec:starsbars}
\# of ways to put $n$ indistinguishable objects in $k$ groups in $\binom{n+k-1}{k-1}$\\
\textbf{Example:} Partitioning n indistinguishable knights into k castles\\
Here, we can think of the castles as barriers. Thus, the problem becomes the standard stars and bars problem, and can be solved with $\binom{n+k-1}{k-1}$ \\
\textbf{Example:} Integer Equations
\begin{center}
    $a_1+a_2+a_3+a_4 + a_5 = 33$
\end{center}
\underline{How many solutions of positive integers:} $\binom{37}{4}$ since we want to split 33 among 5 variables\\
\underline{Find the number of solutions where at least one variable is less than or equal to 3:} $\binom{37}{4}-\binom{12}{4}$ since we can use counting with complement to subtract the solutions where every number is at least 5 from the total number of solutions.\\
\newpage
\underline{How many solutions of integers where $0\leq a_1\leq 10$, $0\leq a_2\leq 10$, $0\leq a_3\leq 10$, $0\leq a_4\leq 10$, and $0\leq a_5\leq 10$:} $\binom{37}{4}-(\binom{5}{1}\binom{26}{4} - \binom{5}{2}\binom{15}{4} + \binom{5}{3}\binom{4}{4})$ since we consider the cases where we give one, two, or three variable at least 11 in order to break the rule. For the term $\binom{5}{1}\binom{26}{24}$ we account for how many different sets of 1 variable we can select to add11 to and how many ways to distribute the remaining 22 among the variables. We have to consider the inclusion exclusion principle since we have to consider all the cases when one, two, or three variables have a minimum of 11. We subtract the total number of ways that don't satisfy the inequalities from the total number of solutions in order to get the answer.\\
\subsection{The 12-fold way}
\label{sec:12fold}
\begin{tabular}{|c|c|c|c|c|}
    \hline
    Elements of $N$ & Elements of $X$ & Any $f$ & $f$ injextive & $f$ surjective\\
    \hline
    Distinguishable & Distinguishable & $x^n$ & $P(X, N)$ & inclusion/exclusion, counting with complement \\
    Indistinguishable & Distinguishable & $\binom{n+x-1}{x-1}$ & $\binom{X}{N}$ & $\binom{n-1}{x-1}$/at least one item in each group\\
    \hline
\end{tabular}
%
\section{Distributions and Probability}
\label{sec:probability}
\subsection{Basics}
\label{sec:pbasics}
\textbf{Sample Space:} A set where outcomes in probability are elements of the sample space\\
\textbf{Events:} subsets of the sample space
\begin{center}
    sample space of rolling a six-sided die is $\{1,2,3,4,5,6\}$
\end{center}
\textbf{Distribution:} A function from the sample space to [0,1]\\
$f: \Omega \rightarrow [0,1]$
\subsection{Uniform/Non-uniform Distribution}
\label{sec:uniform}
Given sample space $S$, in a uniform distribution, for any event $E$, $p(E)=|E|/|S|$\\
Non-uniform distributions: Any distribution that is not uniform, i.e. all events do NOT have the same probability.
\subsection{Binomial Distribution}
\label{sec:binomial_distribution}
\textbf{Bernoulli Trial:} a performance of an experiment with two possible outcomes\\
\textbf{Binomial distribution:} probability of exactly $k$ successes in $n$ independent Bernoulli trials, when the probability of success is $p$.
\begin{center}
Prob($k$)$ = \binom{n}{k}p^k(1-p)^{n-k}$
\end{center}
\subsection{Conditional Probability}
$P(A|B) = \frac{P(A \cap B)}{P(B)}$
\subsection{Bayes Theorem}
\label{sec:bayes}
\textbf{Bayes Theorem:}
$P(A|B) = \frac{P(B|A)P(A)}{P(B)}=\frac{P(B|A)P(A)}{\sum_jP(B|A_i)P(A_I)}$\\
\textbf{Law of Total Probability:} $P(E) = P(E|F)P(F) + P(E|\overline{F})P(\overline{F})$\\
\textbf{Generalized Law of Total Probability:} $P(A) = \sum_jP(A_j|B)P(B)=\sum_jP(A_j \cap B)$
\label{sec:conditional}
\subsection{Independence}
\label{sec:independence}
Two events E and F are independent if the occurence of one event does not affect the likelihood of the other event\\
$P(E|F) = P(E)$\\
$P(E \cap F) = P(E)P(F)$
\subsection{Random Sampling}
Rejection Sampling: Given a uniform distribution, rejection sampling only takes samples if they're within some region of the distribution\\

\textbf{Example:} Simulating a die with a coin\\
Here, we'll flip a coin 3 times, giving us 8 potential outcomes. We'll assign 6 outcomes to a side on the die, then reject two outcomes. If we get our rejected outcomes, we will reflip the coin 3 times.\\
\label{sec:rsampling}
\subsection{Random Variables}
\label{sec:rvariables}
A random variable $X$ assigns a real number to each possible outcome of an experiment ($X: S \rightarrow \mathbb{R})$\\
The distribution of a random variable $X$ is the function $r \rightarrow P(X=r)$
\subsection{Expectation}
\label{sec:expectation}
The expectation (weighted average/ average expected value) of a random variable $X$ on a sample space S is $E(X) = \sum_{s \in S}P(s)X(s)$
\textbf{Example:} What is the expectation of rolling two dice where $X$ is the sum of the value on each die?\\
$E(x) = 2(\frac{1}{36}) + 3(\frac{1}{18}) + 4(\frac{1}{12}) + 5(\frac{1}{9}) + 6(\frac{5}{36}) + 7(\frac{1}{6}) + 8(\frac{5}{36}) + 9(\frac{1}{9}) + 10(\frac{1}{12}) + 11(\frac{1}{18}) + 12(\frac{1}{36}) = 7$
\newpage
\subsubsection{Linearity of Expectation}
\label{sec:lexpectation}
\textbf{Law of Total Expectation:} We can split up the expectation of a random variable into the expectation over a partition of the subspace.\\
\textbf{Indicator Functions}: Useful tool for calculating expectation with law of total expectation. It is defined in the following way:\\
$X_i = \begin{cases}
    1 & \textbf{event occurs}\\
    0 & \textbf{otherwise}
\end{cases}$\\
\textbf{Example:} Suppose 10 dancers select their dresses in a non-uniform way. First, five dancers are randomly picked, and the order in which they're picked determines their color (red is always first, polka-dot second, etc...). The last 5 dancers have their dress color uniformly sampled. What is the expected number of patterns that are only worn by one dancer?\\
Let X represent the number of patterns worn only once, E(X) the expected number of patterns worn only once, and $X_i$ be an indicator variable representing if a dress is worn once.\\
$X_i = \begin{cases}
    1 & \textbf{If pattern is worn only once}\\
    0 & \textbf{otherwise}
\end{cases}$\\
Then,\\
$E(x) = \sum_{i=1}^5(E(X_i))=\\
\sum_{i=1}^5(P(X_i=1)1)=\\
\sum_{i=1}^5((\frac{4}{5}^5)(1))\\
\approx 1.64$]\newpage
\subsection{Variance}
\label{sec:variance}
\textbf{Unexpectedness}:
$U=|X-E|$, where $X$ is random variable and $E$ is expected value\\
\textbf{Average unexpectedness:}
$AU(X) = E(|X-E|)=E(U)$\\
\textbf{Variance:}
$V(X)=E(|X-E|^2)=E(U^2)$\\
\textbf{Standard deviation:}
$\sigma(X)=(E(|X-E|^2))^{\frac{1}{2}}=V(X)^{\frac{1}{2}}$\\
If $X$ and $Y$ are independent, then $V(X+Y)=V(X)+V(Y)$\\
\textbf{Example:} Let you and your friend be equally good at tennis, so that you both have a $\frac{1}{2}$ chance of winning. Let $X_n$ be the win differential. Calculate $E(X_n)$ and the variance of $X_n$:\\
\begin{itemize}
    \item The expected value is 0. Take for example the win differential after one game. It can either be $-1$ or $1$, so the differential is 0. After 2 games, it can either be $2$, $0$, or $-2$. This can be shown more rigorously with the equation $X_n = \sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i)) = 0$\\
    \item The variance is n. As the number of matches goes up, the random variable can vary from the mean by n because either player can have a win differential of $n$ or $-n$. We can show this rigorously:
    $V(X) =
    E(X^2)-(E(X))^2=
    \sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i))^2 - (\sum_{i=0}^n(\binom{n}{i}p^i(1-p)^{n-i}(i-(n-i)))^2=n$
\end{itemize}

\section{Runtime Analysis}
\label{sec:runtime}
\subsection{Min Sort}
\label{sec:minsort}
Given a list, we start by search iterate over the list starting from the first element to find the lowest value which is then swapped with the first element. We then find the lowest value starting from the second index and swap the second lowest value with second element. We continue this patter of finding the lowest value up to the $n-1$ element where $n$ is the number of elements.\\
\begin{tabular}{c c|c|c|c}
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & {\color{red}5} & {\color{red}3} & {\color{red}2} & {\color{red}4} \\
     & {\color{green}2} & {\color{red}3} & {\color{red}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{red}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{red}5}\\
      & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{green}5}\\
\end{tabular}
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ (ordered elements) & $n-1$ (cyclically shift ordered elements) \\
    comparisons & $\frac{n(n-1)}{2}$ &  $\frac{n(n-1)}{2}$
\end{tabular}
\subsection{Bubble Sort}
\label{sec:bubblesort}
Start at the first two elements and swap them if they are out of order. Continue with the second and third element, etc... until we are at the end of the list. Repeat this process from the beginning, reducing the index where we stop each time (every run through the list sorts the ending elements).\\
\begin{tabular}{c c|c|c|c}
    Run 1:\\
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & 5 & 3 & 2 & 4 \\
    & 3 & 5 & 2 & 4 \\
    & 3 & 2 & 5 & 4 \\
    & 3 & 2 & 4 & 5 \\
    Run 2:\\
    & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    & 3 & 2 & 4 & \color{green}{5} \\
    & 2 & 3 & 4 & \color{green}{5} \\
    & 2 & 3 & 4 & \color{green}{5} \\
\end{tabular}\\
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ & $\frac{n(n-1)}{2}$ \\
    comparisons & $n-1$ &  $\frac{n(n-1)}{2}$
\end{tabular}

\subsection{Insertion Sort}
\label{sec:insertionsort}
Given a list, we start with the second element and move it left until it is in order. We do this for each element up to the last, and the indices before the element that is being moved are considered to be in sorted order.\\
\begin{tabular}{c c|c|c|c}
     & Index 1 & Index 2 & Index 3 & Index 4\\
         \hline
    Orginal List $\rightarrow$ & {\color{red}5} & {\color{red}3} & {\color{red}2} & {\color{red}4} \\
     & {\color{green}3} & {\color{green}5} & {\color{red}2} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}5} & {\color{red}4}\\
     & {\color{green}2} & {\color{green}3} & {\color{green}4} & {\color{green}5}\\
\end{tabular}
Best/worst case swaps/comparisons\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    swaps &  $0$ (ordered elements) & $\frac{n(n-1)}{2}$ (reverse order elements)\\
    comparisons & $n-1$ &  $\frac{n(n-1)}{2}$
\end{tabular}
\newpage
\subsection{Linear Search}
\label{sec:linearsearch}
Iterate over a list from the first element until item is found. If at the end of the list and item wasn't found, then the item isn't contained in the list.\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    comparisons & $1$ (item at front) &  $n$ (item at end or not present)
\end{tabular}
\subsection{Binary Search}
\label{sec:binarysearch}
Binary search uses three positional arguments, hi, lo, and mid, and narrows down the search region every iteration to find an element in a sorted list. For example, given a list of size n, lo and hi will be 0 and 5 respectively on first iteration, and thus mid will be 2. If the item at mid is greater than the element to search for, mid becomes hi, otherwise mid becomes lo, and the process continues.\\
\textbf{Example}: Finding 3 in $[1,3,4,5,6]$:\\
\begin{tabular}{c|c|c|c|c}
     \color{red}{1} & 3 & \color{green}{4} & 5 & \color{blue}{6} \\
     \color{red}{1} & \color{green}{3} & \color{blue}{4} & 5 & 6 
\end{tabular}\\
After the second iteration, the element is found\\
\begin{tabular}{c|c|c}
     & min & max \\
     \hline
    comparisons & $1$ (item at middle) &  $\lceil{\log_{2}(n+1)}$ (item at ends or not present)
\end{tabular}
\subsection{Asymptotic Classes}
\label{sec:asymptotic}
\subsubsection{Big Theta}
\label{sec:theta}
\textbf{Definition}: $f(n) \in \Theta(g(n))$ if there are constants $C, C', \text{ and } k$ such that $f(n) \leq Cg(n)$ and $g(n) \leq C'f(n)$ for all $n \geq k$. In other words, Big $\Theta$ defines a tightly bound relationship (grows just as fast).\\
\textbf{Limit definition}: $f(n) \in \theta(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c$ is finite and $c \neq 0$
\subsubsection{Big Omega}
\label{sec:omega}
\textbf{Definition}: $f(n) \in \Omega(g(n))$ if there are constants $C \text{ and } k$ such that $f(n) \geq Cg(n)$ for all $n \geq k$. In other words, Big $\Omega$ defines a lower bound relationship.\\
\textbf{Limit definition}: $f(n) \in \Omega(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c > 0$ or $c = \infty$
\subsubsection{Little O}
\label{sec:littleo}
\textbf{Definition}: if $g(n)$ grows strictly faster than $f(n)$, then $f(n) \in o(g(n))$. Put another way, $f(n) \in o(g(n))$ and $f(n) \notin o(g(n)) $\\
\textbf{Limit definition}: $f(n) \in o(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = 0$
\subsubsection{Big O}
\label{sec:bigo}
\textbf{Definition}: $f(n) \in O(g(n))$ if there are constants $C \text{ and }k$ such that $f(n) \leq Cg(n)$ for all $n \geq k$. In other words, $g(n)$ grows just as fast or faster than $f(n)$.\\
\textbf{Limit definition}: $f(n) \in O(g(n))$: $\lim_{x\to\infty} \frac{f(n)}{g(n)} = c$ where $c$ is finite\\
\textbf{Examples}:\\
\begin{itemize}
    \item $2^n \in O(n^2)$\\
    $\lim_(n \rightarrow \infty)\frac{2^n}{n^2} =$ (Apply L'Hopital's rule) \\
    $\lim_(n \rightarrow \infty)\frac{2^n\ln{2}}{2n}$ (Apply L'Hopitals rule\\
    $\lim_(n \rightarrow \infty)\frac{2^n\ln{2}^2}{2} = \infty$ \\
    Thus, the statement is false.
    \item $F_n \in O(2^n)$ where $F_n$ is a function representing the fibonacci sequence.\\
    $F_n = F_{n-1} + F_{n-2}, F_0=1, F_1=1$\\
    Claim: $F_n \leq 2^n$ for all $n \geq 0$\\
    Base cases:\\
    $F_0=1,2^0=1$\\
    $F_1=1, 2^1=2$\\
    Induction step:\\
    Let $k$ be an arbitrary integer such that $k > 1$. \\
    Assume that $F_m \leq 2^m$ for all m in the range $0 \leq m \leq k$.\\
    WTS $F_k \leq 2^k$:\\
    $F_k=F_{k-1}+F_{k-2} \leq 2^{k-1}+2^{k-2} = 2^{k-2}(2+1) \leq 2^{k-2}(4) = 2^k$\\
    Thus, the statement is true.
    
\end{itemize}
\subsubsection{Big O Class Properties}
\label{sec:oproperties}
\textbf{Domination}: If $f(n) \leq g(n)$ for all $n$ then $f(n) \in O(g(n))$\\
\textbf{Transitivity}: If $f(n) \in O(g(n))$ and $g(n) \in O(h(n))$ then $f(n) \in O(h(n))$\\
\textbf{Additivity/ Multiplicativity}: If $f(n) \in O(g(n))$ and $h(n)$ is non-negative then\\ $f(n)+h(n) \in O(g(n)+h(n))$ and $f(n) \cdot h(n) \in O(g(n) \cdot h(n))$\\
\textbf{Sum is maximum}: $f(n) + g(n) \in O(\text{max}\{f(n),g(n)\})$\\
\textbf{Ignoring constants}: For any constant $c$, $c \cdot f(n) \in O(f(n))$
\subsubsection{Growth Rate of Common Functions}
\label{sec:functions}
\scalebox{0.75}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
     1 (fastest) & $\log(\log n)$ & $\log n$ & $(\log n)^k$ & $n$ & $n\log n$ & $n^k$ & $a^n$ & $n!$ & $n^n$ (slowest)\\
     \hline
     constant & double-logarithm & logarithm & poly-logarithm & linear & log-linear & polynomial & exponential & factorial & 
\end{tabular}
}
\subsubsection{Disjoint Lists Function}
\label{sec:disjoint}
Given two sorted lists, $a[1], \dots, a[n]$ and $b[1] , \dots, b[n]$, determine if they are disjoint or not.\\
Method 1:\\
$\text{for i in } 1 \dots n$\\
$\hspace*{1cm} \text{if }\textbf{BinarySearch}((b[1], \dots, b[n]), a[i]) \neq 0$\\
$\hspace*{2cm} \textbf{return }\text{false;}$\\
$\hspace*{1cm} \textbf{return }\text{true;}$\\
Takes $O(nlogn)$ time.\\
Faster ways: Hashmap, double while loop that we implement\\
Method 2, double while loop:\\
$\text{i=1}\\
\text{j=1}\\
\textbf{while }i < n\\
\hspace*{1cm}\textbf{while }j < n\\
\hspace*{2cm}\textbf{if }a[i] = b[j]\textbf{ then}\\
\hspace*{3cm}\textbf{return}\text{ FALSE}\\
\hspace*{2cm} \textbf{else} \\
\hspace*{3cm}\textbf{if } a[i] < b[j]\textbf{ then}\\
\hspace*{4cm} i = i +1\\
\hspace*{3cm}\textbf{if } a[i] > b[j]\textbf{ then}\\
\hspace*{4cm} i = j + 1 \\
\textbf{return}\text{ TRUE}$
\subsection{Product Rule}
\label{sec:rproduct}
If the inner loop runs $O(T_1(n))$ and the outer loop runs $O(T_2(n))$, worst case runtime is $O(T_1(n)T_2(n))$. Note, this is not always a tight bound (total time could be much faster).\\

\subsection{Loop Invariant Induction}
\label{sec:invariant}
 \textbf{Loop Invariant}: A property that remains true after each time the body of a loop is executed.\\
 \textbf{3 Step Plan for iterative algorithm}
 \begin{enumerate}
     \item Look for a loop invariant
     \item Prove that it is an invariant
     \item Use invariant to prove correctness
 \end{enumerate}
 \subsubsection{Selection Sort Loop Invariant Induction}
 \label{sec:selectionsortproof}
 \textbf{Loop Invariant}: After $t$ iterations, the first $t$ elements are in sorted order and the first $t$ elements are the smallest.\\
 \textbf{Base Case}: $(t=0)$ After $0$ iterations,
 \begin{itemize}
     \item The first $0$ elements are in sorted ordered (vacuously true)
     \item The first $0$ elemets are the smalles (vacuously true)
 \end{itemize}
 \textbf{Inductive Hypothesis}: Suppose that for some $t \geq 0$, the loop invariant is true after $t$ iterations.\\
 \textbf{WTS}: The inductive hypothesis is true after $t+1$ iterations\\
 During the $(t+1)$th iteration, the algorithm sets $a_m$ to be the minimum value of $a_{t+1},\dots,a_n$, and $a_m$ is then swapped with $a_{t+1}$. So after the $(t+1)$th iteration, $a_{t+1}$ is the minimum value of $a_{t+1},\dots,a_n$.\\
 By the inductive hypothesis, $a_1,\dots,a_t$ are in sorted order and are the smallest $t$ elements. Therefore we have that $a_1,\dots,a_t$ are all less than $a_{t+1}$ and $a_{t+1}$ is less than all of $a_{t+1},\dots,a_n$, so $a_1,\dots,a_{t+1}$ are the smallest $(t+1)$ elements of the original list. Additionally, we have that $a_1,\dots,a_t$ are all in sorted order and since $a_1,\dots,a_t$ are all less than $a_{t+1}$, $a_1,\dots,a_{t+1}$ are all in sorted order.
 \subsubsection{Find Max Loop Invariant Induction}
 \textbf{Invariant}: After each iteration, max is the maximum value of the list $(a[1], a[2])(i=2)$.\\
 Proof:\\
 \textbf{Base case}: After 0 iterations, max is maximum $(a[1])$. After one iteration, max is the maximum of $(a[1], a[2]) \ (i=2)$\\
 Let $t \geq 1$ be an arbitrary integer.\\
 Assume that after t iterations, max is a maximum of $(a_1,\dots, a_t)$.\\
 Let $i'=i+1$. \textbf{WTS} after t+1 iterations, max is a maximum of $(a_1,\dots, a_{i'})$.\\
 During the t+1 iteration, $i'=i+1$. There are two cases to consider:\\
Case 1: $a_i' > \text{max}$. max is maximum of $a_1,\dots,a_i$. Thus, the maximum is $a_i'$, and max updates to be $a_i'$. Therefore, max is a maximum of $(a_1,\dots, a_{i'}$.\\
Case 2: $a_i' < \text{max}$. max is maximum of $a_1,\dots,a_i$ and max never updates. Therefore, max is a maximum of $(a_1,\dots, a_{i'}$.\\
 
 \label{sec:findmaxproof}
\end{spacing}
\end{document}
